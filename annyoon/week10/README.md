# 공유 자원과 경쟁 상태 그리고 임계 영역

## 공유 자원(Shared Resource)

시스템 안에서 각 프로세스, 스레드가 함께 접근할 수 있는 모니터, 프린터, 메모리, 파일, 데이터 등의 자원이나 변수를 의미

## 경쟁 상태(Race Condition)

공유 자원을 둘 이상의 프로세스 또는 스레드가 동시에 읽거나 쓰는 상황을 말하며 동시에 접근을 시도할 때의 타이밍이 예상되는 결과 값에 영향을 줄 수 있는 상태를 의미

## 임계 영역(Critical Section)

둘 이상의 프로세스 또는 스레드가 공유 자원에 접근할 때 순서 등의 이유로 결과가 달라지는 코드 영역

이 영역은 한번에 둘 이상의 프로세스나 스레드가 들어갈 수 없게 설계

## 경쟁 상태 관리의 중요성

경쟁 상태를 잘 해결하지 못하면 데이터 정합성, 데이터 무결성을 지키지 못할 수 있음

### 데이터 정합성(Data Consistency)

예상되는 데이터의 값과 다른 것 → 데이터 값이 서로 일치하는 상태

### 데이터 무결성(Data Integrity)

데이터의 어떠한 규칙을 위반하면 안되는 것 → 데이터 값이 정확한 상태

데이터가 전송, 저장되고 처리되는 모든 과정에서 변경되거나 손상되지 않고 완전성, 정확성, 일관성을 유지함을 보장하는 특성

<br>

# 뮤텍스, 세마포어, 모니터

경쟁 상태를 해결하는 대표적인 방법으로는 위 3가지가 있음

이들은 상호 배제, 한정 대기, 진행의 융통성 조건을 만족시키며 경쟁 상태를 해결

- 상호 배제(Mutual Exclusion) : 한 프로세스가 임계 영역에 들어갔을 때 다른 프로세스는 들어갈 수 없음

- 한정 대기(Bounded Waiting) : 특정 프로세스가 임계 영역 진입을 요청한 후 해당 요청이 승인되기 전까지 다른 프로세스가 임계 영역에 진입하는 횟수를 제한하는 것 → 이를 통해 특정 프로세스가 영원히 임계 영역에 들어가지 못하게 하는 것을 방지

- 진행의 융통성(Progress) : 만약 어떠한 프로세스도 임계 영역을 사용하지 않는다면 임계 영역 외부의 어떠한 프로세스도 들어갈 수 있으며 이 때 프로세스끼리 서로 방해하지 않는 것

## 뮤텍스(Mutex)

공유 자원을 `lock()`을 통해 잠금 설정하고 사용한 후에 `unlock()`을 통해 잠금 해제가 되는 객체 `lock`을 기반으로 경쟁 상태를 해결

잠금이 설정되면 다른 프로세스나 스레드는 잠긴 코드 영역에 접근할 수 없고 해제는 그와 반대가 됨

한번에 하나의 프로세스만 임계 영역에 있을 수 있음

## 세마포어(Semaphore)

일반화된 뮤텍스

간단한 정수 `S`와 두 가지 함수 `wait()` 및 `signal()`로 공유 자원에 대한 접근 처리

이를 통해 여러 프로세스가 동시에 임계 영역에 접근 가능

- `S`는 현재 쓸 수 있는 공유 자원의 수

- `wait()`는 `S`를 1씩 감소시키다가 만약 `S`가 음수가 된다면 공유 자원을 쓸 수 없기 때문에 프로세스가 차단되며 대기열에 프로세스를 집어넣음

- `signal()`은 `S`를 1씩 증가시키며(공유 자원을 프로세스가 다 쓴 상태) 이 때 만약 `S`가 0 이하라면 대기열에 있던 프로세스가 동작

- `signal()`은 `V()` 라고도 하며 `wait()`는 `P()`라고도 함

### 바이너리 세마포어

0과 1 두 가지 값만 가질 수 있는 세마포어

구현의 유사성으로 인해 뮤텍스는 바이너리 세마포어라고 할 수 있지만 엄밀히 말하면 뮤텍스는 잠금을 기반으로 상호 배제가 일어나는 **잠금 메커니즘**을 사용했고, 세마포어는 신호를 기반으로 상호 배제가 일어나는 **신호 메커니즘**을 사용한 점이 다름

- 신호 메커니즘 예시: 핸드폰에서 노래를 듣다가 전화가 오면 노래가 중지되고 통화 처리 작업에 관한 인터페이스가 등장하는 것

### 카운팅 세마포어

여러 개의 값을 가질 수 있는 세마포어

## 모니터(Monitor)

둘 이상의 스레드나 프로세스가 공유 자원에 안전하게 접근할 수 있도록 공유 자원을 숨기고 해당 접근에 대해 **인터페이스**만 제공하는 객체

이를 통해 공유 자원에 대한 작업들을 순차적으로 처리

## 모니터와 세마포어의 차이

모니터는 세마포어보다 구현하기 쉬우며 한번에 하나의 프로세스만 공유 자원에 접근할 수 있음 → 상호 배제가 자동이며 인터페이스를 기반으로 구축

세마포어는 모니터보다 구현하기 어려우며 한번에 여러 개의 프로세스가 공유 자원에 접근할 수 있음 → 상호 배제를 명시적으로 구현해야 하며 정수 변수를 기반으로 구축

<br>

# 교착 상태(Deadlock)

두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태

이 과정에서 각 프로세스는 서로가 원하는 자원을 유지한 채 다른 프로세스의 자원을 얻기를 기다림

## 교착 상태의 원인

교착 상태가 발생하기 위한 4가지 필요조건

- 상호 배제: 주어진 시간 내에 하나의 프로세스만 자원을 독점할 수 있음(다른 프로세스들은 접근이 불가능)

- 점유 대기: 특정 프로세스가 점유한 자원을 다른 프로세스가 요청하며 대기하는 상태

- 비선점: 다른 프로세스의 자원을 강제적으로 가져올 수 없음

- 환형 대기: 프로세스 A는 프로세스 B의 자원을 요구하고, 프로세스 B는 프로세스 A의 자원을 요구하는 등 서로가 서로의 자원을 요구하는 상황

위 4가지 조건이 모두 충족되어도 교착 상태는 발생하지 않을 수 있지만 4가지 조건이 모두 충족되어야만 교착 상태가 일어날 수 있음

## 교착 상태의 해결 방법

1. 자원을 할당할 때 애초에 조건이 성립되지 않도록 설계

2. 교착 상태 가능성이 없을 때만 자원 할당되며, 프로세스당 요청할 자원들의 최대치를 통해 자원 할당 가능 여부를 파악하는 **은행원 알고리즘** 사용

3. 교착 상태가 발생하면 사이클이 있는지 찾아보고 이에 관련된 프로세스를 한 개씩 삭제

4. 교착 상태는 매우 드물게 일어나기 때문에 이를 처리하는 비용이 더 커서 교착 상태가 발생하면 사용자가 작업을 종료(현대 운영체제는 이 방법을 채택 → 예를 들어 프로세스를 실행시키다 `응답 없음`이 뜨는 경우 교착 상태가 발생했을 수 있음)

## 은행원 알고리즘(Banker's Algorithm)

교착 상태를 회피하는 알고리즘으로 총 자원의 양과 현재 할당한 자원의 양을 기준으로 안정 또는 불안정 상태로 나누고 안정 상태로 가도록 자원을 할당하는 알고리즘

- 안정 상태: 교착 상태를 일으키지 않은 상태이며 프로세스의 최대 자원 요구량을 운영체제가 충족시킬 수 있는 상태

- 불안정 상태: 안정 상태로 가는 순서열이 존재하지 않는 상태

### 은행원 알고리즘의 단점

프로세스가 시스템에 들어갈 때 필요한 최대 자원 수를 예측해야 하는데 이를 예측하기가 쉽지 않고 해당 알고리즘에 대한 자원 소모량이 증가하게 되며 프로그램의 수는 고정되어있지 않고 항상 변하기 때문에 사용이 어려움

<br>

# CPU 스케줄링 알고리즘 #1. 비선점형(FCFS, SJF, 우선순위)

스케줄링 알고리즘을 통해 CPU가 어떤 프로세스를 선택할 것인지 결정하며 아래 사항과 같이 효율적으로 선택하는 것이 중요

1.  CPU 사용률이 높은가?

2.  단위 시간당 작업을 마친 프로세스의 수(처리량)가 높은가?

3.  작업을 요청한 프로세스가 작업을 시작하기 전 대기하는 시간이 짧은가?

비선점형과 선점형 방식으로 나누어짐

### 비선점형 방식(Non-preemptive)

프로세스가 스스로 CPU 소유권을 포기하는 방식이며 강제로 프로세스를 중지하지 않음 → 컨텍스트 스위칭으로 인한 부하가 적음

## FCFS(First Come, First Served)

가장 먼저 온 것을 가장 먼저 처리하는 알고리즘

길게 수행되는 프로세스 때문에 준비 큐에서 오래 기다리는 현상(Convoy Effect)이 발생하는 단점

## SJF(Shortest Job First)

실행 시간이 가장 짧은 프로세스를 가장 먼저 실행하는 알고리즘

긴 시간을 가진 프로세스가 실행되지 않는 현상(Starvation)이 일어날 수 있는 단점

평균 대기 시간이 가장 짧음

그러나 실제로는 실행 시간을 알 수 없기 때문에 과거에 실행했던 시간을 토대로 추측해서 사용

## 우선순위

기존 SJF 스케줄링의 경우 긴 시간을 가진 프로세스가 실행되지 않는 현상이 있었기 떄문에 오래된 작업일 수록 **우선순위를 높이는 방법(Aging)**을 통해 이 단점을 보완한 알고리즘

우선순위는 작업의 시간, 프로세스의 메모리 요구사항, 열린 파일 수, 평균 CPU 사용량 등을 고려해서 설정

- 우선순위 알고리즘은 SJF + 우선순위 뿐만 아니라 FCFS를 활용하여 만들기도 하며 선점형, 비선점형적인 우선순위 스케줄링 알고리즘을 말하기도 함

<br>

# CPU 스케줄링 알고리즘 #2. 선점형(라운드 로빈 SRF, 다단계 큐)

### 선점형 방식(Preemptive)

**현대 운영체제가 쓰는 방식**으로 지금 사용하고 있는 프로세스를 알고리즘에 의해 중단시켜 버리고 강제로 다른 프로세스에서 CPU 소유권을 할당할 수 있는 방식

## 라운드 로빈(Round Robin, RR)

현대 컴퓨터가 쓰는 스케줄링 방법이며 단순한 선점형 알고리즘

각 프로세스는 동일한 할당 시간을 주고 그 시간 안에 끝나지 않으면 다시 준비 큐(Ready Queue)의 뒤로 가는 알고리즘

- 예를 들어 `q`만큼의 할당 시간이 부여되었고 `N`개의 프로세스가 운영된다고 하면 `(N - 1) * q`시간이 지나면 자기 차례가 오게 됨

할당 시간이 너무 크면 FCFS가 되고 짧으면 컨텍스트 스위칭이 잦아져서 오버헤드, 즉 비용이 커짐

일반적으로 전체 작업 시간은 길어지지만 평균 응답 시간은 짧아지는 특징이 있으며 로드밸런서 트래픽 분산 알고리즘으로도 쓰임

## SRF(Shortest Remaining Time First)

중간에 실행 시간이 더 짧은 작업이 들어와도 기존 짧은 작업을 모두 수행하고 그 다음 짧은 작업을 이어나가는 SJF와는 다르게 중간에 더 짧은 작업이 들어오면 수행하던 프로세스를 중지하고 해당 프로세스를 수행하는 알고리즘

## 다단계 큐

우선순위에 따른 준비 큐를 여러 개 사용하고, 큐마다 라운드 로빈이나 FCFS 등 다른 스케줄링 알고리즘을 적용한 것

큐 간의 프로세스 이동이 안되므로 스케줄링 부담이 적지만 유연성이 떨어지는 특징

우선순위가 높은 큐부터 처리되기 때문에 낮은 큐의 프로세스가 처리되지 않는 기아현상(Starvation)이 발생할 수 있음

비선점형 알고리즘으로만 이루어진 다단계 큐 스케줄링 알고리즘도 있음

<br>

# 캐시 #1. 캐시히트와 캐시미스

## 캐시

데이터를 미리 복사해놓는 임시 저장소

빠른 장치와 느린 장치에서 속도 차이에 따른 병목 현상을 줄이기 위한 메모리

이를 통해 데이터 접근 시간 단축, 데이터를 다시 계산 하는 등의 시간 절약 가능

- 캐시의 대표적인 예시는 CPU 레지스터: CPU가 메모리로부터 데이터를 가져올 때의 시간이 너무 크기 떄문에 그 중간에 레지스터 계층을 둬서 속도 차이를 해결

### 캐시히트

캐시에서 원하는 데이터를 찾은 것

### 캐시미스

캐시에서 원하는 데이터를 찾지 못한 것

캐시미스가 일어나면 메로리로 가서 원하는 데이터를 레지스터에 등록할 수 있음

## 캐시 - 지역성의 원리

캐시를 설정할 때는 자주 사용하는 데이터를 기반으로 설정하며 지역성을 기반으로 설정

### 시간 지역성(Temporal Locality)

최근 사용한 데이터에 다시 접근하려는 특성

### 공간 지역성(Spatial Locality)

최근 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성

<br>

# 캐시 #2. 캐시 매핑: 직접 매핑, 연관 매핑, 집합 연관 매핑

캐시의 크기는 메모리보다 항상 작기 때문에 효율적으로 매핑하는 것이 중요하며 매칭 방식에는 직접 매핑, 연관 매핑, 집합 연관 매핑이 있음

## 직접 매핑(Direct Mapping)

메모리의 특정 블록은 특정 캐시 라인에만 매핑할 수 있는 것

운영체제는 메모리를 똑같은 크기의 페이지(보통 4kb)로 나눠서 관리를 하며 `<P, D>`로 나누어 관리

`P`는 페이지 번호(Page Number)이며 `D`는 페이지 번호부터 해당 주소까지의 거리(Page Offset)를 의미

## 연관 매핑(Associative Mapping)

순서를 일치시키지 않고 관련 있는 캐시와 메모리를 매핑하며 메모리의 컨텐츠가 캐시의 어느 위치에도 올라갈 수 있는 방법

스와핑이 덜 일어나겠지만 캐시의 모든 블록을 탐색해야 해서 직접 매핑보다 속도가 느림

## 집합 연관 매핑(Set Associate Mapping)

집합을 나누고 해당 집합에는 bd(block distance)만 같으면 들어올 수 있게 하는데 이 때 어떤 블록에도 들어올 수 있게 하는 것

모든 블럭을 찾을 필요 없이 특정 블럭을 찾게 해 탐색 비용을 낮춘 직접 매핑의 장점과 스와핑을 완화시키는 연관 매핑의 장점을 모두 갖게 됨

<br>

# 메모리 할당 #1. 연속 할당: 고정 분할과 가변 분할

프로그램에 필요한 메모리를 할당할 때 시작 메모리 위치, 메모리 할당 크기를 기반으로 연속 할당과 불연속 할당으로 나누어짐

### 연속 할당(Contiguous Memory Allocation)

메모리에 **연속적으로** 공간을 할당

사용 가능한 모든 메모리 공간이 같은 위치에 함께 있음(메모리 파티션이 전체 메모리 공간에 여기저기 분산되어 있지 않음)

고정 분할 방식과 가변 분할 방식이 있음

## 고정 분할 방식(Fixed Partition Allocation)

메모리를 미리 같은 크기로 분할해서 할당하는 방법이며 내부 단편화가 발생

### 내부 단편화(Internal Fragmentation)

프로그램이 필요한 공간보다 더 많은 메모리가 할당되어 내부적으로 조각이 많이 생기는 것

이를 통해 추후에 프로그램에 필요한 메모리를 할당하지 못하는 현상이 일어남

## 가변 분할 방식(Variable Partition Allocation)

프로그램에 필요한만큼 동적으로 할당하는 방법

내부 단편화는 발생하지 않으며 외부 단편화가 발생할 수 있음

최초 적합, 최적 적합, 최악 적합이 있음

### 외부 단편화

동적으로 할당한 외부에 작은 조각들이 생기는 현상

조각들을 합하면 충분한 공간이 있지만 외부의 조각들이 되어있기 때문에 큰 프로그램이 들어왔을 때 메모리를 할당할 수 없는 현상이 발생

- 최초적합(First Fit): 위쪽이나 아래쪽부터 시작해 홀을 찾으면 바로 할당

- 최적적합(Best Fit): 필요한 메모리 크기 이상인 공간 중 가장 작은 홀부터 할당

- 최악적합(Worst Fit): 프로세스의 크기와 가장 많이 차이가 나는 홀에 할당

홀(Hole)은 할당할 수 있는 비어 있는 메모리 공간

<br>

# 메모리 할당 #2. 불연속 할당 : 페이징, 세그멘테이션, 페이지드 세그멘테이션

## 불연속할당(Non-contiguous Memory Allocation)

메모리를 연속적으로 할당하지 않는 방법으로 현대 운영체제가 쓰는 방법

프로그램에 필요한 메모리를 쪼개어 서로 다른 위치에 있는 메모리 공간에 할당

대표적으로 페이징, 세그멘테이션, 페이지드 세그멘테이션 기법이 있음

### 페이징(Memory Paging)

동일한 크기(보통 4kb)의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당

홀의 크기가 균일하지 않은 문제가 없어지지만 주소 변환을 페이지별로 해야 하기 때문에 주소 변환이 복잡해지는 단점

4kb짜리 프로세스를 똑같은 크기(2kb)로 나누어서 할당할 수 있기 때문에 외부 단편화가 해결되지만 내부 단편화가 생길 수 있음

### 세그멘테이션(Memory Segmentation)

페이지 단위가 아닌 의미 단위인 세그먼트(Segment)로 나누는 방식

프로세스는 코드, 데이터, 스택, 힙으로 나누어져서 메모리가 할당되는데 코드와 데이터 또는 코드와 스택 등으로 나눌 수도 있으며 함수 단위로 나눌 수도 있음을 의미

공유와 보안 측면에서 좋지만 홀 크기가 균일하지 않게 되어 내부 단편화가 해결될 수 있지만 외부 단편화가 일어날 수 있음

### 페이지드 세그멘테이션(Paged Segmentation or Segmentation with Paging)

세그멘테이션으로 나누되 해당 세그멘테이션을 동일한 크기의 페이지로 나누는 방법
